---
sidebar_position: 2
---

# Transformer

Transformer是2017年由Google提出的革命性架构，完全基于注意力机制，摒弃了传统的循环和卷积结构。

## 算法原理

### 从RNN到Transformer的演进

传统的序列模型（如RNN、LSTM）存在一个根本性问题：**序列处理是串行的**。这意味着：
- 计算第100个词时，必须等待前99个词处理完成
- 无法并行计算，训练速度慢
- 长距离依赖难以建模

Transformer的核心思想是：**用注意力机制完全替代循环结构**，实现并行计算。

### 注意力机制的直观理解

想象你在阅读一篇文章时，理解某个词的含义：
- 你不仅看这个词本身
- 还会关注与它相关的其他词
- 这种"关注"的强度是不同的

这就是注意力机制：**让模型学会关注输入序列中最重要的部分**。

### 自注意力机制

**核心思想**：序列中的每个位置都可以直接关注到序列中的任何位置，包括自己。

**计算过程**：
1. **查询(Query)**：当前词想要什么信息
2. **键(Key)**：其他词能提供什么信息  
3. **值(Value)**：其他词的实际内容
4. **注意力权重**：通过Query和Key的相似度计算
5. **加权求和**：用注意力权重对Value进行加权求和

## 算法关键部分

### 多头注意力机制

**为什么需要多头？**
- 单个注意力头只能学习一种类型的依赖关系
- 多头允许模型同时关注不同类型的信息
- 比如：语法关系、语义关系、位置关系等

**多头注意力的计算**：
$$MultiHead(Q,K,V) = Concat(head_1, ..., head_h)W^O$$

其中每个头：
$$head_i = Attention(QW_i^Q, KW_i^K, VW_i^V)$$

### 位置编码

**问题**：自注意力机制本身没有位置信息，无法区分"我吃苹果"和"苹果吃我"。

**解决方案**：添加位置编码
$$PE_{(pos,2i)} = \sin(pos/10000^{2i/d_{model}})$$
$$PE_{(pos,2i+1)} = \cos(pos/10000^{2i/d_{model}})$$

**为什么用正弦和余弦？**
- 可以表示相对位置关系
- 可以外推到训练时未见过的序列长度
- 数学上便于计算

### 前馈网络

**作用**：对注意力输出进行非线性变换，增加模型的表达能力。

**结构**：
$$FFN(x) = \max(0, xW_1 + b_1)W_2 + b_2$$

这是一个两层全连接网络，中间使用ReLU激活函数。

### 残差连接和层归一化

**残差连接**：$x + Sublayer(x)$
- 解决梯度消失问题
- 允许信息直接传递

**层归一化**：$LayerNorm(x + Sublayer(x))$
- 稳定训练过程
- 加速收敛

## 面试常见问题

### 1. 为什么Transformer比RNN更适合长序列？

**并行计算优势**：
- **RNN**：必须串行计算，时间复杂度O(n)
- **Transformer**：可以并行计算，时间复杂度O(1)（不考虑注意力计算）

**长距离依赖**：
- **RNN**：信息传递路径长，容易梯度消失
- **Transformer**：任意两个位置都可以直接交互

**实际效果**：
- Transformer在机器翻译、文本摘要等任务上显著优于RNN
- 训练速度提升数倍
- 可以处理更长的序列

### 2. 自注意力机制的计算复杂度如何？

**时间复杂度**：O(n²d)，其中n是序列长度，d是特征维度

**空间复杂度**：O(n²)，需要存储注意力矩阵

**为什么是O(n²)？**
- 每个位置都要与所有位置计算注意力
- 序列长度增加时，计算量平方增长
- 这是Transformer的主要瓶颈

**优化方法**：
- **稀疏注意力**：只计算部分位置的注意力
- **局部注意力**：只关注局部窗口
- **线性注意力**：用线性复杂度近似注意力

### 3. 多头注意力中，不同头学习到的是什么？

**实验观察**：
- **语法头**：学习句法依赖关系，如主谓关系
- **语义头**：学习语义相似性，如同义词关系
- **位置头**：学习位置信息，如相邻词关系
- **长距离头**：学习长距离依赖关系

**为什么多头有效？**
- 不同类型的依赖关系需要不同的表示方式
- 多头提供了多种"视角"来理解序列
- 类似于集成学习的思想

### 4. 位置编码为什么用正弦和余弦？

**数学性质**：
- **相对位置编码**：$PE_{pos+k}$可以表示为$PE_{pos}$的线性组合
- **外推能力**：可以处理训练时未见过的序列长度
- **唯一性**：不同位置有不同的编码

**具体公式**：
$$PE_{(pos,2i)} = \sin(pos/10000^{2i/d_{model}})$$
$$PE_{(pos,2i+1)} = \cos(pos/10000^{2i/d_{model}})$$

**为什么这样设计？**
- 不同频率的正弦波可以表示不同的位置信息
- 低频表示粗略位置，高频表示精细位置
- 数学上便于计算和优化

### 5. Transformer的梯度消失问题如何解决？

**问题分析**：
- 深层网络中，梯度在反向传播时逐渐衰减
- 导致深层参数难以更新
- 影响模型性能

**解决方案**：
- **残差连接**：$x + Sublayer(x)$，允许梯度直接传播
- **层归一化**：稳定梯度分布，加速收敛
- **注意力机制**：提供多条信息传播路径

**效果**：
- Transformer可以训练很深的网络（如GPT-3有96层）
- 梯度传播更稳定
- 训练收敛更快

### 6. 如何理解Transformer的"注意力"？

**直观理解**：
- 就像人类阅读时的注意力分配
- 不同词的重要性不同
- 重要性是动态计算的

**数学表达**：
$$Attention(Q,K,V) = softmax(\frac{QK^T}{\sqrt{d_k}})V$$

**注意力权重的含义**：
- 权重越大，表示该位置越重要
- 权重分布反映了模型的"关注点"
- 可以通过可视化理解模型行为

### 7. Transformer在哪些任务上表现突出？

**自然语言处理**：
- **机器翻译**：BLEU分数显著提升
- **文本摘要**：ROUGE分数大幅改善
- **问答系统**：准确率显著提高
- **文本分类**：在多个数据集上达到SOTA

**计算机视觉**：
- **图像分类**：Vision Transformer (ViT)
- **目标检测**：DETR等基于Transformer的检测器
- **图像生成**：DALL-E等生成模型

**多模态任务**：
- **图像描述**：CLIP等跨模态模型
- **视觉问答**：结合图像和文本理解
- **视频理解**：处理时序视觉信息

### 8. Transformer的局限性是什么？

**计算复杂度**：
- 注意力机制的计算复杂度是O(n²)
- 长序列处理困难
- 内存消耗大

**数据需求**：
- 需要大量训练数据
- 小数据集上容易过拟合
- 预训练模型依赖大

**可解释性**：
- 注意力权重难以解释
- 模型决策过程不透明
- 调试困难

**位置信息**：
- 位置编码是固定的
- 无法处理变长序列的位置关系
- 相对位置建模有限
